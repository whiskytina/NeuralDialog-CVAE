{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generated file\n",
    "# return: 1. file of generated sentence/postags\n",
    "#         2. a map of src to generated sentence/postags\n",
    "\n",
    "ROOT_PATH = \"./working/c2c_char_level/topic_cVAE.with_cluster_id.with_wordcut/run1510563558/\"\n",
    "input_file = ROOT_PATH + \"test.txt\"\n",
    "\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "def preprocess(gen_sen):\n",
    "    EOS_SET = set(['.', '。', '?', '？', \"!\", \"！\"])\n",
    "    words = []\n",
    "    postags = []\n",
    "    for w, p in pseg.cut(\"\".join(gen_sen.split(\" \")).decode(\"utf8\")):\n",
    "        words.append(w)\n",
    "        postags.append(p)\n",
    "        if w in EOS_SET:\n",
    "            break\n",
    "    return \" \".join(words).encode(\"utf8\"), \" \".join(postags).encode(\"utf8\")\n",
    "\n",
    "def load_gen_comments(gen_file):\n",
    "    gen_result = {}\n",
    "    words_file = open(gen_file + \".words\", 'w')\n",
    "    postags_file = open(gen_file + \".postags\", 'w')\n",
    "    with open(gen_file, 'r') as fin:\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"Batch\"):\n",
    "                src = \"\"\n",
    "            elif line.startswith(\"Src\"):\n",
    "                src += line[11:-4] + \"\\n\"\n",
    "            elif line.startswith(\"Sample\"):\n",
    "                gen = line.split(\">>\", 1)[1].strip()\n",
    "                if \"<unk>\" in gen:\n",
    "                    continue\n",
    "                words, postags = preprocess(gen)\n",
    "                gen_result.setdefault(src, [])\n",
    "                gen_result[src].append((words, postags))\n",
    "                print >> words_file, words\n",
    "                print >> postags_file, postags\n",
    "    return gen_result\n",
    "\n",
    "gen_comments = load_gen_comments(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lm_score(raw_file, score_file):\n",
    "    raw_data = [line.strip() for line in open(raw_file, 'r')]\n",
    "    score_data = [line.strip() for line in open(score_file, 'r')]\n",
    "    assert(len(raw_data) == len(score_data))\n",
    "    \n",
    "    return zip(raw_data, score_data)\n",
    "\n",
    "def lm_filter(lm_score, pos_thre, eos_thre, seq_thre):\n",
    "    \"\"\"\n",
    "    pos_thre: threshold for each position\n",
    "    eos_thre: threshold of eos position\n",
    "    seq_thre: threshold for each sequence\n",
    "    return: a dict of valid sequence and its score\n",
    "    \"\"\"\n",
    "    keeped_seqs = {}\n",
    "    for seq, score in lm_score:\n",
    "        if score == \"OOV\":\n",
    "            continue\n",
    "            \n",
    "        keep = True\n",
    "        score = map(float, score.split(\"\\t\"))\n",
    "        for s in score[:-2]:\n",
    "            if s < pos_thre:\n",
    "                keep = False\n",
    "                break\n",
    "        if score[-2] < eos_thre:\n",
    "            keep = False\n",
    "        if score[-1] / (len(score) - 1) < seq_thre:\n",
    "            keep = False\n",
    "        \n",
    "        if keep:\n",
    "            keeped_seqs[seq] = score[-1] / (len(score) - 1)\n",
    "    return keeped_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# caculate the RNNLM score of words (in the cmd line)\n",
    "\n",
    "# caculate the RNNLM score of postags (in the cmd line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter ration: 0.00%(108/117247)\n"
     ]
    }
   ],
   "source": [
    "# load the score and do filtering\n",
    "\n",
    "words_lm_score = load_lm_score(ROOT_PATH + \"test.txt.words\", ROOT_PATH + \"test.txt.words.prob\")\n",
    "words_lm_keeped = lm_filter(words_lm_score, pos_thre=-3, eos_thre=-1, seq_thre=-2)\n",
    "\n",
    "print \"filter ration: %.2f%%(%d/%d)\" % (len(words_lm_keeped) * 1.0 / len(words_lm_score), \n",
    "                                        len(words_lm_keeped), len(words_lm_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter ration: 0.01%(1140/117247)\n"
     ]
    }
   ],
   "source": [
    "# load the score and do filtering\n",
    "\n",
    "postags_lm_score = load_lm_score(ROOT_PATH + \"test.txt.postags\", ROOT_PATH + \"test.txt.postags.prob\")\n",
    "\n",
    "postags_lm_keeped = lm_filter(postags_lm_score, pos_thre=-1.5, eos_thre=-1, seq_thre=-1.25)\n",
    "\n",
    "print \"filter ration: %.2f%%(%d/%d)\" % (len(postags_lm_keeped) * 1.0 / len(postags_lm_score), \n",
    "                                        len(postags_lm_keeped), len(postags_lm_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover: 0.05% (16/355)\n"
     ]
    }
   ],
   "source": [
    "# output the final result\n",
    "\n",
    "total_num = 0\n",
    "gen_num = 0\n",
    "with open(ROOT_PATH + \"final_result.txt\", 'w') as fout:\n",
    "    for src, gens in gen_comments.items():\n",
    "        total_num += 1\n",
    "        valid_gens = []\n",
    "        for words, postags in gens:\n",
    "            if words in words_lm_keeped and \\\n",
    "                postags in postags_lm_keeped:\n",
    "                valid_gens.append((words, words_lm_keeped[words]))\n",
    "        if len(valid_gens) == 0:\n",
    "            continue\n",
    "        gen_num += 1\n",
    "        valid_gens = sorted(valid_gens, key=lambda x: x[1], reverse=True)\n",
    "        print >> fout, \"src: %s\" % src.strip()\n",
    "        for i, (gen, score) in enumerate(valid_gens):\n",
    "            print >> fout, \"gen%02d: %s (%.2f)\" % (i, gen, score)\n",
    "        print >> fout, \"\"\n",
    "        \n",
    "print \"Cover: %.2f%% (%d/%d)\" %(gen_num * 1.0 / total_num, gen_num, total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
