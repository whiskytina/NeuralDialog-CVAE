{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool, Manager\n",
    "from tqdm import tqdm\n",
    "from hashlib import md5\n",
    "\n",
    "class NgramModel():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_data(self, train_data_file):\n",
    "        self.train_data = []\n",
    "        with open(train_data_file, 'r') as fin:\n",
    "            for line in fin:\n",
    "                self.train_data.append([\"<s>\"] + line.strip().split(\" \") + [\"</s>\"])\n",
    "        \n",
    "                \n",
    "    def unsmoothed_n_grams(self, n, num_thread=4):\n",
    "        word_count = {}\n",
    "        \n",
    "        def ngrams(lst_words, n):\n",
    "            if len(lst_words) < n:\n",
    "                return \n",
    "            for i in range(len(lst_words) - n + 1):\n",
    "                key = \" \".join(lst_words[i:i+n])\n",
    "                key = md5(key).hexdigest()\n",
    "                word_count.setdefault(key, 0)\n",
    "                word_count[key] += 1\n",
    "                \n",
    "        for lst_words in tqdm(self.train_data):\n",
    "            ngrams(lst_words, n)\n",
    "        \n",
    "        return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16898316/16898316 [05:50<00:00, 48273.50it/s]\n",
      " 22%|██▏       | 3692160/16898316 [01:22<05:09, 42618.55it/s]"
     ]
    }
   ],
   "source": [
    "model = NgramModel()\n",
    "\n",
    "model.load_data(\"../data/comment_corpus_for_lm.train.txt\")\n",
    "\n",
    "unigram = model.unsmoothed_n_grams(1)\n",
    "bigram = model.unsmoothed_n_grams(2)\n",
    "trigram = model.unsmoothed_n_grams(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pkl\n",
    "\n",
    "pkl.dump((unigram, bigram, trigram), open(\"./DQD_vocab.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pkl\n",
    "\n",
    "unigram, bigram, trigram = pkl.load(open(\"./DQD_vocab.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hashlib import md5\n",
    "from math import log\n",
    "\n",
    "ROOT_PATH = \"../../working/c2c_char_level/kgcVAE_with_BOW_loss/run1509882751/\"\n",
    "\n",
    "test_file = ROOT_PATH + \"test.txt.words\"\n",
    "output_file = ROOT_PATH + \"test.txt.words.ngram.prob\"\n",
    "\n",
    "V = vocab_size = len(unigram)\n",
    "\n",
    "def get_prob(word_seq):\n",
    "    \"\"\"\n",
    "    word_seq: [\"<s>\", ..., \"</s>\"]\n",
    "    return: [prob, ...]\n",
    "    \"\"\"\n",
    "    assert(len(word_seq) > 2)\n",
    "    probs = []\n",
    "    sum_prob = 0.0\n",
    "    for i in range(0, len(word_seq)-2):\n",
    "        tri_key = md5(\" \".join(word_seq[i:i+3])).hexdigest()\n",
    "        tri_count = trigram.get(tri_key, 0) + 1\n",
    "        bi_key = md5(\" \".join(word_seq[i:i+2])).hexdigest()\n",
    "        bi_count = bigram.get(bi_key, 0) + V\n",
    "        logprob = log(tri_count * 1.0 / bi_count)\n",
    "        probs.append(logprob)\n",
    "        sum_prob += logprob\n",
    "    probs.append(sum_prob)\n",
    "    return probs\n",
    "\n",
    "with open(test_file, 'r') as fin:\n",
    "    with open(output_file, 'w') as fout:\n",
    "        for line in fin:\n",
    "            word_seq = [\"<s>\"] + line.strip().split(\" \") + [\"</s>\"]\n",
    "            probs = get_prob(word_seq)\n",
    "            print >> fout, \"\\t\".join(map(str, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
